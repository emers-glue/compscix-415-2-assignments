---
title: "COMPSCIX 415.2 Homework 5/Midterm"
author: "Emerson Sosa"
date: "3/2/2019"
output: 
   html_document:
     theme: darkly
     highlight: espresso
     code_folding: hide
     toc: true
     collapsed: true
     number_sections: true
     toc_depth: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, warning=FALSE, message=FALSE}
library(ggplot2)
library(tidyverse)
library(dplyr)
```

https://github.com/emers-glue/compscix-415-2-assignments

# <font color=#873f05>The tidyverse packages</font>

<font color=#F38812 size=4> *1. Can you name which package is associated with each task below?*</font>


1. Plotting: For plotting, use the <font color=blue>`ggplot2`</font> package.
2. Data munging/wrangling: For data wrangling use the <font color=blue>`dplyr`</font> package.
3. Reshaping data: To reshape the data use the <font color=blue>`tidyr`</font> package.?
4. Importing/exporting data: For importing and exporting, use the <font color=blue>`readr`</font> package.

<font color=#F38812 size=4> *2. Now can you name two functions that you've used from each package that you listed above for these tasks?*</font>

1. Plotting: In conjunction with <font color=blue>`ggplot2`</font>, I have used the <font color=blue>`geom_point()`</font> and <font color=blue>`geom_count()`</font> for visualizing data. 
2. Data munging/wrangling: The <font color=blue>`filter()`</font> function has been very useful for me and I have admired the power of the <font color=blue>`summarise()`</font> when used with the <font color=blue>`group_by()`</font> function.
3. Reshaping data: Understanding the usage of <font color=blue>`gather()`</font> and <font color=blue>`spread()`</font> will be essential when colloborating with others as it cannot be assumed that they will be using tidy data. 
4. Importing/exporting data: To import data, use <font color=blue>`read_csv()`</font> to import and <font color=blue>`write_csv()`</font> to export as a csv. file. 

# <font color=#873f05>R Basics</font>

<font color=#F38812 size=4> *1. Fix this code with the fewest number of changes possible so it works:*</font>

I added quote marks around the tag to allow the exclamation point.

```{r}
('My_data.name___is.too00ooLong!' <- c( 1 , 2   , 3 ))
```


<font color=#F38812 size=4> *2. Fix this code so it works:* </font>

To fix, I changed the case of the concatenation function to lower case and added a quote end mark to <i>it</i>.

```{r}
(my_string <- c('has', 'an', 'error', 'in', 'it'))
```


<font color=#F38812 size=4> *3. Look at the code below and comment on what happened to the values in the vector.* </font>

R does not need quotes around numbers when making them a vector. When quotes are placed around them, R forces the exact input inside. For example, if a space is placed inside the quote marks, r will print that extra space as well. The same is not true when adding extra spaces to numbers without quotes around the number. 

```{r}
my_vector <- c(1,2, '3', '4', 5)
my_vector
```


# <font color=#873f05>Data import/export</font>

<font color=#F38812 size=4> *1. Download the rail_trail.txt file from Canvas and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.*</font>

```{r}
rail.trail.path <- 
  'rail_trail.txt'
rail.trail.data <-
  read_delim('rail_trail.txt', delim = '|')
glimpse(rail.trail.data)
```


<font color=#F38812 size=4>*2. Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.* </font>

```{r}
write_csv(rail.trail.data, 'rail.trail.csv')
rail.trail.csv <-
  read_csv('rail.trail.csv')
glimpse(rail.trail.csv)
```


# <font color=#873f05>Visualization</font>

<font color=#F38812 size=4>*1. Critique this graphic: give only three examples of what is wrong with this graphic.*</font>

1. The choice in colors for the genders is a bit confusing. A byproduct of our patriarchal society lends colors like pink and purple being femenized, therefore it is a bit hard to detach the color from women. It would have been better to assign gender nuetral colors instead. 
2. The tidy data does not adhere to the tidy data tenets because gender is clumped into two observations instead of being spread across the ages. It would have been better to spread the genders across age groups instead to see if there are distinctions there. 
3. The presentations of the circles in this graphic also presents the problem of relative sizes. It is hard to distinguish the magnitude of each circle just by looking at the sizes and the inclusion of the value of each cirlce is really needed to sift through the sizes of each. It would have been better to do some sort of bar graph allowing the reader to quickly distinguish the difference in sizes by the height of each observation. 

<center><img src="https://i.imgur.com/z4E79r1.jpgAMAYAwBgDAGAMAYAwD/2Q==" ></center>

<font color=#F38812 size=4>*2. Reproduce this graphic using the diamonds data set.*</font>

<img src="https://i.imgur.com/FnaWNcD.jpg">

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = carat, fill = color)) +
  geom_boxplot(position = 'identity') +
  labs(x ="CUT OF DIAMOND", y ="CARAT OF DIAMOND") + 
  coord_flip() +
  scale_fill_manual(values=c("#cc5b39", "#918612", "green", "#1bbaac", "#52b4e5", "#8f6dd6", "#e54ed6")) 

```

<font color=#F38812 size=4>*3. The previous graphic is not very useful. We can make it much more useful by changing one thing about it. Make the change and plot it again.*</font>

By changing the position from `'identity'` to `'dodge'`, the color group is more distinct and not crowded.

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, y = carat, fill = color)) +
  geom_boxplot(position = 'dodge') +
  labs(x ="CUT OF DIAMOND", y ="CARAT OF DIAMOND") + 
  coord_flip() +
  scale_fill_manual(values=c("#cc5b39", "#918612", "green", "#1bbaac", "#52b4e5", "#8f6dd6", "#dd38e2"))
```


# <font color=#873f05>Data munging and wrangling</font>

<font color=#F38812 size=4>*1. Is this data “tidy”? *</font>

No, the data was not tidy because it needed spreading because there were two variables in `type`. The `spread()` function was used. 

```{r}
(table2)
table2 %>% 
  spread(key = type, value = count)
```

<font color=#F38812 size=4>*2. Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output.*</font>


`diamonds %>% mutate(price_per_carat = price/carat)` 



<font color=#F38812 size=4>*3. For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit. Do the results make sense? Why? Do we need to be wary of any of these numbers? Why?*</font>

834 diamonds (1.5% from the total amount of diamonds) have a price > 10000 and a carat < 1.5. Diamonds that have a carat of 1.0 - 1.3 have about the same price. If one assumes that the most important factor for price is carat, than this data seems suspect. Because of this plateau in the data, more information on the diamonds in this particular region would be needed such as color, cut, etc. 

```{r warning=FALSE, message=FALSE}

(filter(diamonds, price > 10000 & carat < 1.5)) %>% 
   count()
n.spec.diamonds <- filter(diamonds, price > 10000 & carat < 1.5) %>% 
   count()

(n.spec.diamonds/count(diamonds) *100)

spec.diamonds <- (filter(diamonds, price > 10000 & carat < 1.5))

top.diam <- select(spec.diamonds, price, carat) %>% 
  filter(price > 10000)

ggplot(top.diam, aes(carat, price)) +
  geom_smooth()
ggplot(diamonds, aes(carat, price)) +
  geom_smooth()
```

# <font color=#873f05>EDA</font>

<font color=#F38812 size=4>*1. During what time period is this data from?*</font>

The data is for the years of 2000-2015.

```{r}
?txhousing
distinct(txhousing, year)

```


<font color=#F38812 size=4>*2. How many cities are represented?*</font>

46 "cities" are represented.

```{r}
distinct(txhousing, city)
```


<font color=#F38812 size=4>*3. Which city, month and year had the highest number of sales?*</font>


Houston had the highest number of sales with 1,043,999

June had the highest number of sales.

2006 had the highest number of sales.

```{r warning=FALSE, message=FALSE}
sales.per.city <- arrange(txhousing, city, sales) %>% 
  group_by(city) %>% 
  summarise(sales = sum(sales))
ggplot(sales.per.city, aes(city, sales))+
  geom_col()
arrange(sales.per.city, desc(sales))

ggplot(txhousing, aes(month, sales)) +
  geom_col()

select(txhousing, year, sales) %>% 
  group_by(year) %>% 
  summarise(sales.per.year = sum(sales, na.rm = TRUE)) %>% 
  arrange(desc(sales.per.year))
```


<font color=#F38812 size=4>*4. What kind of relationship do you think exists between the number of listings and the number of sales?  Check your assumption and show your work.*</font>

The assumption is that there would be more sales given more listings but would taper off a certain level given the economics of supply and demand. Using `geom_smooth`, one can see that there is a strong positive correlation between sales and listings but slows down as the listings increase over 20000.

```{r warning=FALSE, message=FALSE}
ggplot(txhousing, aes(listings, sales)) +
  geom_smooth()
```


<font color=#F38812 size=4>*5. What proportion of sales is missing for each city?*</font>

This question was confusing because after sorting the data, there were no cities with missing sales values. After further combing, one city was close to fulfilling this criteria: San Marcos had only 6 sales in October of 2011. There were missing values in listings but since the questions was not in relation to listings, I did not do the analysis.  

```{r}
(missing.sales <- txhousing %>% 
  filter(is.na(city)))

(not.missing.sales <- txhousing %>% 
  filter(!is.na(city)))

(not.missing.listings <- txhousing %>% 
  filter(!is.na(listings)))

```

```{r}
(txhousing %>% 
  select(city, sales, month, year) %>% 
  arrange(!desc(sales))) %>% 
  filter(sales < 9)
  

```


<font color=#F38812 size=4>*6. Looking at only the cities and months with greater than 500 sales: Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work. Any cities that stand out that you’d want to investigate further? Why might we want to filter out all cities and months with sales less than 500?*</font>

The distributions of the median sales price when grouped by city and month are different. There is more variation when looking at city. The data is more homogenous for months. Collin County has the highest median sale price which is interesting as, per wikipedia, only has a population of less than 800,000 people. Having a filter of more than 500 sales ensures a large enough sample size so that outliers don't affect the average median sale price.  

```{r warning=FALSE, message=FALSE}
(five.hundred <- txhousing %>%
  filter(sales > 500)) 

(city.500 <- five.hundred %>% 
  group_by(city) %>% 
  summarise(median = mean(median)) %>% 
  arrange(desc(median)))
 
month.500 <- five.hundred %>% 
  group_by(month) %>% 
  summarise(median = mean(median))

ggplot(month.500, aes(month, median)) +
  geom_point() + 
  geom_smooth()

ggplot(city.500, aes(city, median)) +
  geom_point() +
  geom_smooth() +
  coord_flip()
 

```


